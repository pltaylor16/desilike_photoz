; We will carry out a joint Hybrid pipeline analysis of 
; DES Y3 xi_pm and KiDS-1000 COSEBIS including scale cuts (2'<theta_min<300')
[DEFAULT]
DATAfile=${COSMOSIS_STD_DIR}/likelihood/des-y3_and_kids-1000/DES-Y3_xipm_and_KiDS-1000_COSEBIs_2.0_300.0.fits
RUN_NAME = des-y3_and_kids-1000

[pipeline]
modules =   consistency camb extrapolate 
            fits_nz_des correlated_dz_priors fits_nz_kids photoz_bias_des photoz_bias_kids 
            fast_pt choose_des_ia IA 
            pk_to_cl_des add_intrinsic 2pt_shear shear_m_bias 2pt_like 
            choose_kids_ia IA 
            pk_to_cl_kids add_intrinsic cosebis cosebis_like
likelihoods = 2pt cosebis
values  = ${INI_FILE_DIR}/des-y3_and_kids-1000-values.ini
priors  = ${INI_FILE_DIR}/des-y3_and_kids-1000-priors.ini
extra_output =  cosmological_parameters/sigma_8 
                cosmological_parameters/A_s cosmological_parameters/omega_m 
                cosmological_parameters/omega_lambda cosmological_parameters/cosmomc_theta 
                delta_z_out_kids/bin_1 delta_z_out_kids/bin_2 delta_z_out_kids/bin_3 
                delta_z_out_kids/bin_4 delta_z_out_kids/bin_5 
                delta_z_out_des/bin_1 delta_z_out_des/bin_2 delta_z_out_des/bin_3 
                delta_z_out_des/bin_4 
                data_vector/2pt_chi2 likelihoods/cosebis_like likelihoods/2pt_like
timing = F
debug = T

; Since CosmoSIS v3, the consistency interface allows for sampling over S8
; Here we set up the non-linear power spectrum
[consistency]
file=${COSMOSIS_STD_DIR}/utility/consistency/consistency_interface.py

[camb]
file=${COSMOSIS_STD_DIR}/boltzmann/camb/camb_interface.py
mode = all
halofit_version = mead2020_feedback  
neutrino_hierarchy = normal
lmax=2500
kmax=100.0
zmid = 2.0
nz_mid = 100
zmax = 6.0
nz = 150
feedback=0

[extrapolate]
file=${COSMOSIS_STD_DIR}/boltzmann/extrapolate/extrapolate_power.py
kmax = 500.

; Next we define the redshift bins and how we're going to marginalise over
; our uncertainty on these distributions
[fits_nz_des]
file=${COSMOSIS_STD_DIR}/number_density/load_nz_fits/load_nz_fits.py
nz_file=${COSMOSIS_STD_DIR}/%(DATAFILE)s
data_sets = source_des

; This module allows for correlated priors for KiDS given a covariance matrix
[correlated_dz_priors]
file=${COSMOSIS_STD_DIR}/number_density/correlated_priors/correlated_priors.py
uncorrelated_parameters =   nofz_shifts_kids/uncorr_bias_1 nofz_shifts_kids/uncorr_bias_2 
                            nofz_shifts_kids/uncorr_bias_3 nofz_shifts_kids/uncorr_bias_4 
                            nofz_shifts_kids/uncorr_bias_5
output_parameters = nofz_shifts_kids/bias_1 nofz_shifts_kids/bias_2 
                    nofz_shifts_kids/bias_3 nofz_shifts_kids/bias_4 
                    nofz_shifts_kids/bias_5
covariance = likelihood/des-y3_and_kids-1000/nofz_covariance/SOM_cov_multiplied.asc

[fits_nz_kids]
file=${COSMOSIS_STD_DIR}/number_density/load_nz_fits/load_nz_fits.py
nz_file=${COSMOSIS_STD_DIR}/%(DATAFILE)s
data_sets = source_kids

[photoz_bias_des]
file=${COSMOSIS_STD_DIR}/number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source_des
bias_section = wl_photoz_errors_des
interpolation = cubic
output_deltaz_section_name = delta_z_out_des

[photoz_bias_kids]
file=${COSMOSIS_STD_DIR}/number_density/photoz_bias/photoz_bias.py
mode = additive
sample = nz_source_kids
bias_section = nofz_shifts_kids
interpolation = cubic
output_deltaz_section_name = delta_z_out_kids

; Here we are using the TATT modules for our IA model
; to allow for flexibility in extensions to our fiducial analyses
; The hybrid set-up uses NLA-z, with the non-NLA parameters
; in the TATT model set to zero in the values file

[fast_pt]
file=${COSMOSIS_STD_DIR}/structure/fast_pt/fast_pt_interface.py
do_ia = T
k_res_fac = 0.5
verbose = F

; In our fiducial analysis we allow for the DES and KiDS
; surveys to have independent IA parameters.  Call choose_ia_params
; and it updates the IA parameter name before the IA module is called
[choose_des_ia]
file=${COSMOSIS_STD_DIR}/intrinsic_alignments/choose_ia/choose_ia_params.py
suffix = des

[IA]
file=${COSMOSIS_STD_DIR}/intrinsic_alignments/tatt/tatt_interface.py
sub_lowk=F
do_galaxy_intrinsic=F
ia_model=tatt

; As DES and KiDS are assumed to be uncorrelated we can 
; calculate the likelihoods independently

; We start with DES
[pk_to_cl_des]
file=${COSMOSIS_STD_DIR}/structure/projection/project_2d.py
ell_min_logspaced = 0.1
ell_max_logspaced = 5.0e5
n_ell_logspaced = 100
shear-shear = source_des-source_des
shear-intrinsic = source_des-source_des
intrinsic-intrinsic = source_des-source_des
intrinsicb-intrinsicb = source_des-source_des
verbose = F
get_kernel_peaks = F
sig_over_dchi = 20.
shear_kernel_dchi = 10.

[add_intrinsic]
file=${COSMOSIS_STD_DIR}/shear/add_intrinsic/add_intrinsic.py
shear-shear=T
position-shear=F
perbin=F

[2pt_shear]
file=${COSMOSIS_STD_DIR}/shear/cl_to_xi_fullsky/cl_to_xi_interface.py
ell_max = 40000
xi_type = EB
theta_file=${COSMOSIS_STD_DIR}/%(DATAFILE)s
bin_avg = T
; these get
input_section_name = shear_cl  shear_cl_bb
output_section_name = shear_xi_plus  shear_xi_minus

[shear_m_bias]
file=${COSMOSIS_STD_DIR}/shear/shear_bias/shear_m_bias.py
m_per_bin = True
; Despite the parameter name, this can operate on xi as well as C_ell.
cl_section = shear_xi_plus shear_xi_minus
verbose = F

; This is the DES Y3 2pt_likelihood module.  It's all-singing all-dancing
; covering xi_pm, gamma_t and wtheta. 
; Don't be confused by the name "point mass" in the title.
; This point only concerns the likelihood calculation of the GGL statistic
; which we're not analysing here (data_sets = xip xim)
[2pt_like]
file=${COSMOSIS_STD_DIR}/likelihood/2pt/2pt_point_mass/2pt_point_mass.py
do_pm_marg = True
do_pm_sigcritinv = True
sigma_a = 10000.0
no_det_fac = False
include_norm = False
data_file=${COSMOSIS_STD_DIR}/%(DATAFILE)s
data_sets = xip xim
covmat_name=COVMAT
; The scale cuts (angle_range_xi*_*_*) are listed in a separate file
; Here we use the LCDM-optimised scale cuts from Amon/Secco/Samuroff et al 2022
%include ${INI_FILE_DIR}/des-y3-LCDM-optimised-scale-cuts.ini


; Now time to move on to KiDS
; First rename the IA parameters so they are independent of the
; IA parameters for DES.  If you want to use the same set of parameters
; for both surveys, remove both instances of this module and update
; the values file accordingly
[choose_kids_ia]
file=${COSMOSIS_STD_DIR}/intrinsic_alignments/choose_ia/choose_ia_params.py
suffix = kids

[pk_to_cl_kids]
file=${COSMOSIS_STD_DIR}/structure/projection/project_2d.py
ell_min_logspaced = 0.1
ell_max_logspaced = 5.0e5
n_ell_logspaced = 100 
shear-shear = source_kids-source_kids
shear-intrinsic = source_kids-source_kids
intrinsic-intrinsic = source_kids-source_kids
intrinsicb-intrinsicb = source_kids-source_kids
verbose = F
get_kernel_peaks = F
sig_over_dchi = 20. 
shear_kernel_dchi = 10.

;This calculates COSEBIs from Cls
[cosebis]
file=${COSMOSIS_STD_DIR}/shear/cosebis/cl_to_cosebis/cl_to_cosebis_interface.so
theta_min = 2.0 ; default=0.5
theta_max = 300.0 ; default=300
n_max = 5 ; default=5
input_section_name = shear_cl
output_section_name = cosebis

;This is a simplified version of the the KiDS-1000 2pt_likelihood module
;which is not all-singing nor all-dancing because we only need to
;analyse COSEBIs for this Joint DES+KiDS analysis
[cosebis_like]
file=${COSMOSIS_STD_DIR}/likelihood/2pt/cosebis/simple_like.py
data_set = En n
data_file=${COSMOSIS_STD_DIR}/%(DATAFILE)s
like_name = cosebis
;If you're interested in using KiDS-1000 data products other than COSEBIs
;The 2pt-likelihood that KiDS-1000 used for their 3x2pt analysis can be found
;on the KiDS-1000 KCAP repo: 
;https://github.com/KiDS-WL/kcap/blob/master/modules/scale_cuts/scale_cuts.py
;https://github.com/KiDS-WL/kcap/blob/master/utils/mini_like.py


; If I run on the command line "cosmosis ${INI_FILE_DIR}/des-y3_and_kids-1000.ini", this will run this quick test sampler.
[runtime]
sampler = test
verbosity = standard
; saving the output to output/des-y3_and_kids-1000
[test]
save_dir=output/%(RUN_NAME)s
fatal_errors=T

; If I run command "cosmosis ${INI_FILE_DIR}/des-y3_and_kids-1000.ini runtime.sampler='polychord'", this will run polychord.
; These are the settings used for the Hybrid DES+KiDS analysis, but be warned it's CPU intensive. 
[polychord]
base_dir = chain_checkpoints
polychord_outfile_root=poly_%(RUN_NAME)s
resume=F
feedback = 3
fast_fraction = 0.1
;Minimum settings for a "good enough" quick test
;live_points = 250
;num_repeats = 30
;tolerance = 0.1
;Settings for high quality paper runs
live_points = 500
num_repeats=60
tolerance=0.01
boost_posteriors=10.0

[output]
filename= chain_%(RUN_NAME)s.txt
format=text
lock=F
privacy=F